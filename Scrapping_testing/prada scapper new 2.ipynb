{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAkxNmEnKSgZ",
        "outputId": "d15aac4a-1695-4616-c979-f421454a5014"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', 'DB_and_Azure'))\n",
        "import sql_db_functions as SQLf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o0F0rDcOrdM",
        "outputId": "5a09e6d1-cc76-4b82-a4d8-392d3a5a6baf"
      },
      "outputs": [],
      "source": [
        "def get_soup(url, retries=3):\n",
        "    \"\"\"Fetch the page content and return the BeautifulSoup object.\"\"\"\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                return BeautifulSoup(response.text, 'html.parser')\n",
        "            else:\n",
        "                print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching the URL: {e}\")\n",
        "        time.sleep(random.uniform(1, 3))  # Random delay between retries\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def scrape_prada_product(url):\n",
        "    soup = get_soup(url)\n",
        "    if not soup:\n",
        "        return None\n",
        "\n",
        "    product = {}\n",
        "\n",
        "    # Add link\n",
        "    product['link'] = url\n",
        "\n",
        "    # Extract product name\n",
        "    title_element = soup.find('h1', {'data-element': 'product-title'})\n",
        "    if title_element:\n",
        "        product['name'] = title_element.text.strip()\n",
        "\n",
        "    # Extract product price\n",
        "    price_element = soup.find('p', {'data-element': 'product-current-price'})\n",
        "    if price_element:\n",
        "        product['price'] = price_element.text.strip()\n",
        "\n",
        "    # Extract product color\n",
        "    color_element = soup.find('div', class_='block mb-sp-8 lg:mb-sp-12 leading-none')\n",
        "    if color_element:\n",
        "        color_name = color_element.find_all('p')[1].text.strip()\n",
        "        product['color'] = color_name\n",
        "\n",
        "    # Extract product sizes\n",
        "    sizes = []\n",
        "    size_elements = soup.select('select[data-element=\"sizepicker\"] option')\n",
        "    for option in size_elements:\n",
        "        if option.get('disabled') is None:  # Only add sizes that are not disabled\n",
        "            sizes.append(option.text.strip())\n",
        "    product['sizes'] = sizes\n",
        "\n",
        "    # Extract product images (first three)\n",
        "    images = []\n",
        "    image_elements = soup.find_all('img', class_='pdp-product-img', limit=3)\n",
        "    for img in image_elements:\n",
        "        if 'data-srcset' in img.attrs:\n",
        "            images.append(img['data-srcset'].split(', ')[-1].split(' ')[0])  # Take the highest resolution image URL\n",
        "\n",
        "    product['images'] = images\n",
        "\n",
        "    # Extract product details\n",
        "    details_element = soup.find('div', {'data-element': 'product-details'})\n",
        "    if details_element:\n",
        "        product['details'] = details_element.text.strip()\n",
        "\n",
        "    # Extract composition\n",
        "    composition_element = soup.find('div', class_='product-composition')\n",
        "    if composition_element:\n",
        "        product['composition'] = composition_element.text.strip()\n",
        "\n",
        "    return product\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_price(prod_soup):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Remove any non-numeric characters except for ',' and '.'\n",
        "    cleaned_text = re.sub(r'[^\\d,\\.]', '', text)\n",
        "    \n",
        "    # Replace comma with a period if there's no period already (to handle decimal part)\n",
        "    if ',' in cleaned_text and '.' not in cleaned_text:\n",
        "        cleaned_text = cleaned_text.replace(',', '.')\n",
        "\n",
        "    elif ',' not in cleaned_text and '.' in cleaned_text:\n",
        "        cleaned_text = cleaned_text.replace('.', '')\n",
        "\n",
        "    elif ',' in cleaned_text and '.' in cleaned_text:\n",
        "        # If both ',' and '.' are present, keep only the period as the decimal separator\n",
        "        cleaned_text = cleaned_text.replace('.', '')\n",
        "        cleaned_text = cleaned_text.replace(',', '.')\n",
        "    \n",
        "    # Convert the string to a float\n",
        "    number = float(cleaned_text)\n",
        "    \n",
        "    return number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_catalog(url, Testing):\n",
        "    soup = get_soup(url)\n",
        "    if not soup:\n",
        "        return []\n",
        "\n",
        "    product_links = [a['href'] for a in soup.select('a[href*=\"/it/en/p/\"]')]\n",
        "    base_url = \"https://www.prada.com\"\n",
        "    full_product_links = [base_url + link for link in product_links]\n",
        "\n",
        "\n",
        "    for link in product_links:\n",
        "        print(f\"Scraping {link}\")\n",
        "        product_data = scrape_prada_product(link)\n",
        "\n",
        "        conn, cursor = SQLf.sql_db_functions.connect_sql()\n",
        "\n",
        "        SQLf.sql_db_functions.insert_description_image_to_db(\n",
        "            conn=conn,\n",
        "            cursor=cursor,\n",
        "            brand='Prada',\n",
        "            descript=product_data['details'],\n",
        "            price=product_data['price'],\n",
        "            prod_link = product_data['link'],\n",
        "            Clothing_type = 'Shirts and tops',\n",
        "            images_links=product_data['images'],\n",
        "            Testing = Testing\n",
        "        )\n",
        "\n",
        "        conn.close()\n",
        "        cursor.close()\n",
        "\n",
        "\n",
        "        #if product_data:\n",
        "        #    products.append(product_data)\n",
        "        time.sleep(random.uniform(3, 6))  # Random delay between product page scrapes\n",
        "\n",
        "        return product_data\n",
        "\n",
        "\n",
        "    #return product_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# URL of the Prada catalog page (example)\n",
        "catalog_url = 'https://www.prada.com/it/en/womens/ready-to-wear/shirts-and-tops/c/10058EU:1'\n",
        "product_data = scrape_catalog(catalog_url, Testing = True)\n",
        "\n",
        "if product_data:\n",
        "    for product in product_data:\n",
        "        print(product)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
