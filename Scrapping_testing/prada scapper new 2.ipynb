{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAkxNmEnKSgZ",
        "outputId": "d15aac4a-1695-4616-c979-f421454a5014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'Striped poplin shirt', 'price': '€ 1.100', 'color': 'Sapphire Blue', 'sizes': [], 'images': ['https://www.prada.com/content/dam/pradabkg_products/P/P43/P436H/15DTF0013/P436H_15DT_F0013_S_OOO_MDF.jpg/_jcr_content/renditions/cq5dam.web.hebebed.1800.1800.jpg', 'https://www.prada.com/content/dam/pradabkg_products/P/P43/P436H/15DTF0013/P436H_15DT_F0013_S_OOO_MDD.jpg/_jcr_content/renditions/cq5dam.web.hebebed.1800.1800.jpg'], 'details': 'ProduktdetailsThis poplin shirt with a classic menswear silhouette is animated by a stripe motif. The style, characterized by the patch pocket on the chest, is enhanced by the emblematic fabric triangle logo reinterpreted with a conceptual design. Produktcode: P436H_15DT_F0013_S_OOOMenswear fitShirt collarFront button closureSleeves with shirt cuffsPatch pocket on the frontTriangle logo with sartorial logo label The model is 178 cm tall and wears a size 38Höhe: 69cm'}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_prada_product(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    product = {}\n",
        "\n",
        "    # Extract product name\n",
        "    title_element = soup.find('h1', {'data-element': 'product-title'})\n",
        "    if title_element:\n",
        "        product['name'] = title_element.text.strip()\n",
        "\n",
        "    # Extract product price\n",
        "    price_element = soup.find('p', {'data-element': 'product-current-price'})\n",
        "    if price_element:\n",
        "        product['price'] = price_element.text.strip()\n",
        "\n",
        "    # Extract product color\n",
        "    color_element = soup.find('div', class_='block mb-sp-8 lg:mb-sp-12 leading-none')\n",
        "    if color_element:\n",
        "        color_name = color_element.find_all('p')[1].text.strip()\n",
        "        product['color'] = color_name\n",
        "\n",
        "    # Extract product sizes\n",
        "    sizes = []\n",
        "    size_elements = soup.find_all('option')\n",
        "    for option in size_elements:\n",
        "        if option.get('disabled') is None:  # Only add sizes that are not disabled\n",
        "            sizes.append(option.text.strip())\n",
        "    product['sizes'] = sizes\n",
        "\n",
        "    # Extract product images (first three)\n",
        "    images = []\n",
        "    image_elements = soup.find_all('img', class_='pdp-product-img', limit=3)\n",
        "    for img in image_elements:\n",
        "        if 'data-srcset' in img.attrs:\n",
        "            images.append(img['data-srcset'].split(', ')[-1].split(' ')[0])  # Take the highest resolution image URL\n",
        "\n",
        "    product['images'] = images\n",
        "\n",
        "    # Extract product details\n",
        "    details_element = soup.find('div', {'data-element': 'product-details'})\n",
        "    if details_element:\n",
        "        product['details'] = details_element.text.strip()\n",
        "\n",
        "    # Extract composition\n",
        "    composition_element = soup.find('div', class_='product-composition')\n",
        "    if composition_element:\n",
        "        product['composition'] = composition_element.text.strip()\n",
        "\n",
        "    return product\n",
        "\n",
        "# URL of the Prada product page (example)\n",
        "url = 'https://www.prada.com/it/en/p/striped-poplin-shirt/P436H_15DT_F0013_S_OOO'\n",
        "product_data = scrape_prada_product(url)\n",
        "\n",
        "if product_data:\n",
        "    print(product_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', 'DB_and_Azure'))\n",
        "import sql_db_functions as SQLf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o0F0rDcOrdM",
        "outputId": "5a09e6d1-cc76-4b82-a4d8-392d3a5a6baf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import random\n",
        "\n",
        "def get_soup(url, retries=3):\n",
        "    \"\"\"Fetch the page content and return the BeautifulSoup object.\"\"\"\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                return BeautifulSoup(response.text, 'html.parser')\n",
        "            else:\n",
        "                print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching the URL: {e}\")\n",
        "        time.sleep(random.uniform(1, 3))  # Random delay between retries\n",
        "    return None\n",
        "\n",
        "def scrape_prada_product(url):\n",
        "    soup = get_soup(url)\n",
        "    if not soup:\n",
        "        return None\n",
        "\n",
        "    product = {}\n",
        "\n",
        "    # Add link\n",
        "    product['link'] = url\n",
        "\n",
        "    # Extract product name\n",
        "    title_element = soup.find('h1', {'data-element': 'product-title'})\n",
        "    if title_element:\n",
        "        product['name'] = title_element.text.strip()\n",
        "\n",
        "    # Extract product price\n",
        "    price_element = soup.find('p', {'data-element': 'product-current-price'})\n",
        "    if price_element:\n",
        "        product['price'] = price_element.text.strip()\n",
        "\n",
        "    # Extract product color\n",
        "    color_element = soup.find('div', class_='block mb-sp-8 lg:mb-sp-12 leading-none')\n",
        "    if color_element:\n",
        "        color_name = color_element.find_all('p')[1].text.strip()\n",
        "        product['color'] = color_name\n",
        "\n",
        "    # Extract product sizes\n",
        "    sizes = []\n",
        "    size_elements = soup.select('select[data-element=\"sizepicker\"] option')\n",
        "    for option in size_elements:\n",
        "        if option.get('disabled') is None:  # Only add sizes that are not disabled\n",
        "            sizes.append(option.text.strip())\n",
        "    product['sizes'] = sizes\n",
        "\n",
        "    # Extract product images (first three)\n",
        "    images = []\n",
        "    image_elements = soup.find_all('img', class_='pdp-product-img', limit=3)\n",
        "    for img in image_elements:\n",
        "        if 'data-srcset' in img.attrs:\n",
        "            images.append(img['data-srcset'].split(', ')[-1].split(' ')[0])  # Take the highest resolution image URL\n",
        "\n",
        "    product['images'] = images\n",
        "\n",
        "    # Extract product details\n",
        "    details_element = soup.find('div', {'data-element': 'product-details'})\n",
        "    if details_element:\n",
        "        product['details'] = details_element.text.strip()\n",
        "\n",
        "    # Extract composition\n",
        "    composition_element = soup.find('div', class_='product-composition')\n",
        "    if composition_element:\n",
        "        product['composition'] = composition_element.text.strip()\n",
        "\n",
        "    return product\n",
        "\n",
        "def scrape_catalog(url):\n",
        "    soup = get_soup(url)\n",
        "    if not soup:\n",
        "        return []\n",
        "\n",
        "    product_links = [a['href'] for a in soup.select('a[href*=\"/it/en/p/\"]')]\n",
        "    base_url = \"https://www.prada.com\"\n",
        "    full_product_links = [base_url + link for link in product_links]\n",
        "\n",
        "\n",
        "    for link in product_links:\n",
        "        print(f\"Scraping {link}\")\n",
        "        product_data = scrape_prada_product(link)\n",
        "\n",
        "        conn, cursor = SQLf.sql_db_functions.connect_sql()\n",
        "\n",
        "        SQLf.sql_db_functions.insert_description_image_to_db(\n",
        "            conn=conn,\n",
        "            cursor=cursor,\n",
        "            brand='Prada',\n",
        "            descript=product_data['details'],\n",
        "            price=product_data['price'],\n",
        "            prod_link = product_data['link'],\n",
        "            Clothing_type = 'Shirts and tops',\n",
        "            images_links=product_data['images'],\n",
        "            Testing = False\n",
        "        )\n",
        "\n",
        "        conn.close()\n",
        "        cursor.close()\n",
        "\n",
        "\n",
        "        #if product_data:\n",
        "        #    products.append(product_data)\n",
        "        time.sleep(random.uniform(3, 6))  # Random delay between product page scrapes\n",
        "\n",
        "        return product_data\n",
        "        break\n",
        "\n",
        "    #return product_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://www.prada.com/it/en/p/printed-silk-twill-shirt/P439H_15GG_F0E18_S_OOO\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "sql_db_functions.insert_description_image_to_db() got an unexpected keyword argument 'Testing'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# URL of the Prada catalog page (example)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m catalog_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.prada.com/it/en/womens/ready-to-wear/shirts-and-tops/c/10058EU:1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m product_data \u001b[38;5;241m=\u001b[39m scrape_catalog(catalog_url)\n",
            "Cell \u001b[1;32mIn[40], line 91\u001b[0m, in \u001b[0;36mscrape_catalog\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     87\u001b[0m product_data \u001b[38;5;241m=\u001b[39m scrape_prada_product(link)\n\u001b[0;32m     89\u001b[0m conn, cursor \u001b[38;5;241m=\u001b[39m SQLf\u001b[38;5;241m.\u001b[39msql_db_functions\u001b[38;5;241m.\u001b[39mconnect_sql()\n\u001b[1;32m---> 91\u001b[0m SQLf\u001b[38;5;241m.\u001b[39msql_db_functions\u001b[38;5;241m.\u001b[39minsert_description_image_to_db(\n\u001b[0;32m     92\u001b[0m     conn\u001b[38;5;241m=\u001b[39mconn,\n\u001b[0;32m     93\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[0;32m     94\u001b[0m     brand\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrada\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     95\u001b[0m     descript\u001b[38;5;241m=\u001b[39mproduct_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetails\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     96\u001b[0m     price\u001b[38;5;241m=\u001b[39mproduct_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     97\u001b[0m     prod_link \u001b[38;5;241m=\u001b[39m product_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     98\u001b[0m     Clothing_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShirts and tops\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     99\u001b[0m     images_links\u001b[38;5;241m=\u001b[39mproduct_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    100\u001b[0m     Testing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    104\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
            "\u001b[1;31mTypeError\u001b[0m: sql_db_functions.insert_description_image_to_db() got an unexpected keyword argument 'Testing'"
          ]
        }
      ],
      "source": [
        "# URL of the Prada catalog page (example)\n",
        "catalog_url = 'https://www.prada.com/it/en/womens/ready-to-wear/shirts-and-tops/c/10058EU:1'\n",
        "product_data = scrape_catalog(catalog_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# URL of the Prada catalog page (example)\n",
        "catalog_url = 'https://www.prada.com/it/en/womens/ready-to-wear/shirts-and-tops/c/10058EU:1'\n",
        "product_data = scrape_catalog(catalog_url)\n",
        "\n",
        "if product_data:\n",
        "    for product in product_data:\n",
        "        print(product)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
